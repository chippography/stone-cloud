{
 "metadata": {
  "name": "",
  "signature": "sha256:004b9f459f4aa7c021404a394ebacb26e84b78150867877604f9f7ede4b11bdc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from freenect import sync_get_depth as get_depth, sync_get_video as get_video\n",
      "import numpy as np\n",
      "import pcl\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.widgets as widgets\n",
      "%pylab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: MacOSX\n",
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Images of Stone Work\n",
      "# The Vision - \n",
      "# - projected contour guidance\n",
      "# - documentation of carving\n",
      "# - why not robot? machine collaboration!\n",
      "# Connect to the Kinect\n",
      "# Zoom Goggles\n",
      "# Segmenting \n",
      "# a 3-D model...\n",
      "# ... placed into the stone\n",
      "# Projection onto the Surface"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Grab a Frame from the Kinect"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get a fresh frame from the Kinect\n",
      "(depth,_), (rgb,_) = get_depth(), get_video()\n",
      "\n",
      "# depth is the raw 11-bit image from the kinect, \n",
      "# where 0 is infinitely far away and larger numbers \n",
      "# are closer to the camera\n",
      "#  (2047 indicates an error pixel)\n",
      "\n",
      "# rgb is the video image from the kinect\n",
      "\n",
      "# Build a two panel color image\n",
      "d3 = np.dstack((depth,depth,depth)).astype(np.uint8)\n",
      "da = np.hstack((d3,rgb))\n",
      "\n",
      "plt.imshow(da) # No XZOOM"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "<matplotlib.image.AxesImage at 0x113535b50>"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(da) # No XZOOM"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 114,
       "text": [
        "<matplotlib.image.AxesImage at 0x1136a7fd0>"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Crop to Area of Interest"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x1, y1, x2, y2 = (0, 0, 480, 640)\n",
      "def onselect(eclick, erelease):\n",
      "    if eclick.ydata>erelease.ydata:\n",
      "        eclick.ydata,erelease.ydata=erelease.ydata,eclick.ydata\n",
      "    if eclick.xdata>erelease.xdata:\n",
      "        eclick.xdata,erelease.xdata=erelease.xdata,eclick.xdata\n",
      "\n",
      "    global x1, y1, x2, y2\n",
      "    x1, y1 = eclick.xdata, eclick.ydata\n",
      "    x2, y2 = erelease.xdata, erelease.ydata\n",
      "\n",
      "    ax.set_ylim(erelease.ydata,eclick.ydata)\n",
      "    ax.set_xlim(eclick.xdata,erelease.xdata)\n",
      "    fig.canvas.draw()\n",
      "\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot(111)\n",
      "plt_image=plt.imshow(d3)\n",
      "\n",
      "rs=widgets.RectangleSelector(\n",
      "    ax, onselect, drawtype='box',\n",
      "    rectprops = dict(facecolor='red', edgecolor = 'red', alpha=0.5, fill=True))\n",
      "\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Convert Depth Image to Point Cloud"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "(377.5645161290322, 342.72580645161281)"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use the intrinsic / extrinsic calibration matrices\n",
      "# to project the kinect depth map into a xyz point cloud\n",
      "from calibkinect import depth2xyzuv\n",
      "\n",
      "# u and v are the selected depth image coordinates,\n",
      "#  (0,0) is the top left corner of the image\n",
      "#  (640,480) is the bottom right corner of the image\n",
      "u,v = np.mgrid[int(x1):int(x2), int(y1):int(y2)]\n",
      "\n",
      "xyz, uv = depth2xyzuv(depth[v,u], u, v)\n",
      "\n",
      "# x,y,z\n",
      "# The 3D world coordinates, in meters, relative to the depth camera. \n",
      "# (0,0,0) is the camera center. \n",
      "# Negative Z values are in front of the camera, and the positive Z direction \n",
      "# points towards the camera. \n",
      "# The X axis points to the right, and the Y axis points up. \n",
      "# This is the standard right-handed coordinate system used by OpenGL.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "(43253, 2)"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xyz32 = xyz.astype(np.float32)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpl_toolkits.mplot3d import axes3d\n",
      "\n",
      "fig = figure()\n",
      "ax = fig.gca(projection='3d')\n",
      "ax.plot(xyz[:,0],xyz[:,1],xyz[:,2], '.')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 116,
       "text": [
        "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x11369e5d0>]"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pc = pcl.PointCloud() # export as a PCD\n",
      "pc.from_array(xyz32)\n",
      "pc.to_file(\"./pc.pcd\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seg = pc.make_segmenter_normals(ksearch=50)\n",
      "seg.set_optimize_coefficients (True)\n",
      "seg.set_model_type(pcl.SACMODEL_NORMAL_PLANE)\n",
      "seg.set_normal_distance_weight (0.1)\n",
      "seg.set_method_type (pcl.SAC_RANSAC)\n",
      "seg.set_max_iterations(100)\n",
      "seg.set_distance_threshold(0.03)\n",
      "indices, model = seg.segment()\n",
      "\n",
      "print model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-0.046032704412937164, 0.010323979891836643, 0.9988865852355957, 0.5936337113380432]\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pc_plane = pc.extract(indices, negative=False)\n",
      "pc_plane.to_file(\"pc_plane.pcd\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = calibkinect.uv_matrix()\n",
      "[-0.19208358,  0.11383015, -0.60231127]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "array([[ -1.02739028e+02,  -5.35826625e-01,   1.92541302e+02,\n",
        "         -0.00000000e+00],\n",
        "       [ -7.48462902e-01,  -6.01983466e+01,   1.57203052e+02,\n",
        "          0.00000000e+00],\n",
        "       [ -0.00000000e+00,   0.00000000e+00,  -0.00000000e+00,\n",
        "          0.00000000e+00],\n",
        "       [ -3.35578082e-03,  -1.39730379e-03,   6.02173943e-01,\n",
        "          0.00000000e+00]])"
       ]
      }
     ],
     "prompt_number": 113
    }
   ],
   "metadata": {}
  }
 ]
}